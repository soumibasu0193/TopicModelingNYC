{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraper_grahim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXl3CztPZlZ_",
        "outputId": "017b2839-2b23-4e31-b1e5-aeba3d987ccf"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "!pip install selenium\n",
        "from selenium import webdriver\n",
        "!apt-get -q update   #Used to handle installation and removal of softwares and libraries\n",
        "!apt install -yq chromium-chromedriver #ChromeDriver is a separate executable that Selenium WebDriver uses to control Chrome.\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver \n",
        "#WebDriver is a browser automation framework that works with open source APIs. \n",
        "#The framework operates by accepting commands, sending those commands to a browser, and interacting with applications.\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "df=pd.DataFrame()\n",
        "\n",
        "##### Web scrapper for infinite scrolling page #####\n",
        "driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "time.sleep(5)  # Allow 2 seconds for the web page to open\n",
        "scroll_pause_time = 5 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
        "screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
        "\n",
        "r = requests.get('https://gramhir.com/profile/nycgov/289258065', params={'wait': 5})\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "        #container = soup.find('div', {'class':'content box-photos-wrapper'})\n",
        "photos =  soup.find_all('div',{'class':'box-photo'})\n",
        "print(len(photos))\n",
        "try:\n",
        "  for photo in photos:\n",
        "    url = photo.find('a')['href']\n",
        "    caption = photo.find(\"div\",{\"class\":\"photo-description\"}).text\n",
        "    likes = photo.find(\"div\",{\"class\":\"likes_photo\"}).text\n",
        "    comments = photo.find(\"div\",{\"class\":\"comments_photo\"}).text\n",
        "        \n",
        "    details = {'caption': caption, 'number of likes': likes, 'number of comments': comments, 'url': url}\n",
        "    df = df.append(details, ignore_index=True)\n",
        "    print(url)\n",
        "except:\n",
        "    print('Encountered error!')\n",
        "\n",
        "# AUTO-Scroll implementation\n",
        "i = 1\n",
        "if(len(photos)<700): \n",
        "          # scroll one screen height each time\n",
        "  driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
        "  i += 1\n",
        "  time.sleep(scroll_pause_time)\n",
        "      # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
        "  scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
        "\n",
        "df.head()\n",
        "df.to_excel(\"nyc_details.xlsx\",index=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "chromium-chromedriver is already the newest version (93.0.4577.63-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "14\n",
            "https://gramhir.com/media/2676398476723746170\n",
            "Encountered error!\n"
          ]
        }
      ]
    }
  ]
}